{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jaxlie import SE3, SO3\n",
    "import orbax\n",
    "import optax\n",
    "import pandas as pd\n",
    "from flax.training import orbax_utils\n",
    "from flax.training.train_state import TrainState\n",
    "from sdf_world.sdf_world import *\n",
    "from sdf_world.robots import *\n",
    "from sdf_world.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_succ = pd.read_csv('./data/003_cracker_box/succ.csv')\n",
    "df_fail = pd.read_csv('./data/003_cracker_box/fail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"x\", \"y\", \"z\", \"d\", \"a1\", \"a2\", \"a3\", \"g1\", \"g2\", \"g3\", \"depth\", \"width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_points = np.random.uniform(-1, 1, [50000,3])\n",
    "df_rand = pd.DataFrame(rand_points, columns=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_succ[\"succ\"] = 1\n",
    "df_rand[\"succ\"] = 0\n",
    "df_fail[\"succ\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_succ, df_rand, df_fail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot6d_to_qtn(rot6d):\n",
    "    z, y = rot6d[:3], rot6d[3:6]\n",
    "    x = jnp.cross(y, z)\n",
    "    R = jnp.vstack([x, y, z]).T\n",
    "    return SO3.from_matrix(R).parameters()\n",
    "rot6d_to_qtn_batch = jax.vmap(rot6d_to_qtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot6ds = jnp.array(df[[\"a1\", \"a2\", \"a3\", \"g1\", \"g2\", \"g3\"]].to_numpy())\n",
    "qtns = rot6d_to_qtn_batch(rot6ds)\n",
    "is_succ = df['succ'].to_numpy()[:,None]\n",
    "inputs = df[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "labels = np.asarray(jnp.hstack([is_succ, qtns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf_world.dataset import NumpyDataset, numpy_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 128\n",
    "grasp_dataset = NumpyDataset(inputs, labels)\n",
    "train_dataset, val_dataset = train_test_split(grasp_dataset, train_size=0.9, shuffle=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=numpy_collate)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class GraspNet(nn.Module):\n",
    "    hidden_dim: int\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=self.hidden_dim)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.hidden_dim)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.hidden_dim)(x)\n",
    "        x = nn.relu(x)\n",
    "        logit = nn.Dense(features=5)(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_loss_qtn(qtn_pred, qtn_true):\n",
    "    normalization = lambda x: x/safe_2norm(x)\n",
    "    qtn_loss = lambda x, y: 1 - jnp.abs(x@y)\n",
    "    flip_z180 = lambda qtn: (SO3(qtn) @ SO3.from_z_radians(jnp.pi)).parameters()\n",
    "\n",
    "    qtn_pred_norm = jax.vmap(normalization)(qtn_pred)\n",
    "    qtn_true_flip = jax.vmap(flip_z180)(qtn_true)\n",
    "    loss1 = jax.vmap(qtn_loss)(qtn_pred_norm, qtn_true)\n",
    "    loss2 = jax.vmap(qtn_loss)(qtn_pred_norm, qtn_true_flip)\n",
    "    return jnp.minimum(loss1, loss2)\n",
    "\n",
    "def grasp_config_loss_fn(pred, label):\n",
    "    _, qtn_pred = pred[:,0], pred[:,1:5]\n",
    "    succ, qtn_true = label[:,0], label[:,1:5]\n",
    "    num_succ_samples = succ.sum()\n",
    "    no_succ = num_succ_samples==0.\n",
    "    den = jnp.where(no_succ, 1., num_succ_samples)\n",
    "    losses_rot = jnp.where(succ, rot_loss_qtn(qtn_pred, jnp.nan_to_num(qtn_true)), 0.).sum()\n",
    "    loss_rot = jnp.where(no_succ, 0., losses_rot/den)\n",
    "    return loss_rot\n",
    "def grasp_loss_qtn_fn(state:TrainState, params, batch):\n",
    "    x, y = batch\n",
    "    pred = state.apply_fn(params, x).squeeze()\n",
    "    p_pred = pred[:,0]\n",
    "    p_true = y[:,0]\n",
    "    loss_p = optax.sigmoid_binary_cross_entropy(p_pred, p_true).mean()\n",
    "    loss_grasp = grasp_config_loss_fn(pred, y)\n",
    "    return loss_p + loss_grasp\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state:TrainState, batch):\n",
    "    losses, grads = jax.value_and_grad(grasp_loss_qtn_fn, argnums=1)(state, state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_net = GraspNet(10)\n",
    "key1, key2 = jax.random.split(jax.random.PRNGKey(0))\n",
    "x = jax.random.normal(key1, (3,)) # Dummy input data\n",
    "params = grasp_net.init(key2, x) # Initialization call\n",
    "tx = optax.adam(learning_rate=0.001)\n",
    "state = TrainState.create(apply_fn=grasp_net.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : losses0.03429203853011131\n",
      "1 : losses0.015390394255518913\n",
      "2 : losses0.08615678548812866\n",
      "3 : losses0.016262270510196686\n",
      "4 : losses0.022181129083037376\n",
      "5 : losses0.03709304332733154\n",
      "6 : losses0.026119589805603027\n",
      "7 : losses0.040343768894672394\n",
      "8 : losses0.047262948006391525\n",
      "9 : losses0.03480619564652443\n",
      "10 : losses0.0408630408346653\n",
      "11 : losses0.009641844779253006\n",
      "12 : losses0.016654474660754204\n",
      "13 : losses0.055467333644628525\n",
      "14 : losses0.05414344370365143\n",
      "15 : losses0.04399104416370392\n",
      "16 : losses0.04738979414105415\n",
      "17 : losses0.05603944510221481\n",
      "18 : losses0.04310968145728111\n",
      "19 : losses0.07680554687976837\n",
      "20 : losses0.03505518287420273\n",
      "21 : losses0.024633269757032394\n",
      "22 : losses0.035928063094615936\n",
      "23 : losses0.04586592689156532\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[285], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m----> 3\u001b[0m         state, losses \u001b[39m=\u001b[39m train_step(state, batch)    \n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m : losses\u001b[39m\u001b[39m{\u001b[39;00mlosses\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cu11/lib/python3.8/site-packages/flax/core/frozen_dict.py:162\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, keys, values)\u001b[0m\n\u001b[1;32m    157\u001b[0m   sorted_keys \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict)\n\u001b[1;32m    158\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m    159\u001b[0m       [(jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mDictKey(k), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m sorted_keys]\n\u001b[1;32m    160\u001b[0m   ), \u001b[39mtuple\u001b[39m(sorted_keys)\n\u001b[0;32m--> 162\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_unflatten\u001b[39m(\u001b[39mcls\u001b[39m, keys, values):\n\u001b[1;32m    164\u001b[0m   \u001b[39m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   \u001b[39m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    166\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m({k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(keys, values)}, __unsafe_skip_copy__\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        state, losses = train_step(state, batch)    \n",
    "    print(f\"{epoch} : losses{losses.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "ckpt = {\n",
    "    \"params\": state.params,\n",
    "    \"hidden_dim\": 10\n",
    "}\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "orbax_checkpointer.save('model/grasp_net', ckpt, save_args=save_args, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import open3d as o3d\n",
    "def to_pointcloud(points:np.ndarray):\n",
    "    points = o3d.utility.Vector3dVector(points)\n",
    "    return o3d.geometry.PointCloud(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_fn = lambda x: grasp_net.apply(state.params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_path = \"sdf_world/assets/object/norm_mesh.obj\"\n",
    "mesh = trimesh.load_mesh(mesh_path)\n",
    "surface_points = mesh.as_open3d.sample_points_uniformly(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = grasp_fn(surface_points.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual, qtns = preds[:,0], preds[:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = qual #- jnp.exp(qual) # + d\n",
    "thres = 0.5\n",
    "bool_idx = v > thres  # jnp.sign(qual) > 0 #d < 0.03 # jnp.sign(qual) == 1\n",
    "fail_bool_idx = v < thres #jnp.sign(qual) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yaxis_from_qtn(qtn):\n",
    "    return SO3(qtn).normalize().as_matrix()[:,1]\n",
    "def get_zaxis_from_qtn(qtn):\n",
    "    return SO3(qtn).normalize().as_matrix()[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_points = jnp.array(surface_points.points)[bool_idx]\n",
    "succ_pc = to_pointcloud(succ_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([succ_pc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
